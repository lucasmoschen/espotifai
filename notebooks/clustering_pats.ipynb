{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## Based on the article [PATS](http://ismir2002.ircam.fr/proceedings/OKPROC02-FP07-4.pdf)\n",
    "\n",
    "The ideia is to establish a similarity metric and do a clusterization process with these metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist, squareform\n",
    "\n",
    "from seaborn import heatmap \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Important Features \n",
    "\n",
    "This features will be used to understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =  ['playlist_id', 'duration_ms', 'explicit', 'id', 'album_type', 'popularity', 'album_id', \n",
    "             'album_release_date', 'artists_ids', 'name', 'artists_names']\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'key', 'mode', 'speechiness', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist and tracks dataframes \n",
    "\n",
    "Getting the data generated by Spotify API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_pickle('../data/sp_playlists.pkl')[['id']]\n",
    "playlists_df['playlist_id'] = playlists_df['id']\n",
    "playlists_df = playlists_df[['playlist_id']]\n",
    "audio_features_df = pd.read_pickle('../data/sp_audio_features.pkl')[audio_features]\n",
    "tracks_df = pd.concat(\n",
    "    [pd.read_pickle(file)[metadata] for file in glob.glob('../data/sp_tracks_ready_*.pkl')],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = audio_features_df.merge(tracks_df, on = 'id')\n",
    "tracks_df = tracks_df.merge(playlists_df, on = 'playlist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "del audio_features_df\n",
    "del playlists_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the dates to datetime and use the year as a continuum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>album_type</th>\n",
       "      <th>popularity</th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>artists_ids</th>\n",
       "      <th>name</th>\n",
       "      <th>artists_names</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49453</th>\n",
       "      <td>0.558</td>\n",
       "      <td>0.855</td>\n",
       "      <td>-5.243</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.00342</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.574</td>\n",
       "      <td>...</td>\n",
       "      <td>340366.0</td>\n",
       "      <td>False</td>\n",
       "      <td>single</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5O5GxUUPKUqrWvtgaFyZnM</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>[4OrizGCKhOrW6iDDJHN9xd]</td>\n",
       "      <td>Bent (Roi's Song)</td>\n",
       "      <td>[DIIV]</td>\n",
       "      <td>2015.927626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       danceability  energy  loudness  key  mode  speechiness  acousticness  \\\n",
       "49453         0.558   0.855    -5.243    2     1       0.0343       0.00342   \n",
       "\n",
       "       instrumentalness  liveness  valence  ...  duration_ms  explicit  \\\n",
       "49453             0.934     0.175    0.574  ...     340366.0     False   \n",
       "\n",
       "      album_type popularity                album_id album_release_date  \\\n",
       "49453     single       18.0  5O5GxUUPKUqrWvtgaFyZnM         2015-11-04   \n",
       "\n",
       "                    artists_ids               name artists_names        years  \n",
       "49453  [4OrizGCKhOrW6iDDJHN9xd]  Bent (Roi's Song)        [DIIV]  2015.927626  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df['album_release_date'] = tracks_df['album_release_date'].apply(lambda x: \n",
    "                                                                        None if x == '0000' else pd.to_datetime(x))\n",
    "tracks_df['years'] = tracks_df['album_release_date'].apply(lambda x: x.year + x.month/12 + x.day/365)\n",
    "tracks_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45 nan values in the years columns. I will put the mean of the values, because it's few missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['years'].fillna(np.mean(tracks_df['years']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separate the catefortical, numerical and set_oriented features, to make the ideia of the similarity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical =  ['explicit', 'album_type', 'album_id', 'key', 'mode', 'time_signature']\n",
    "features_numerical = ['duration_ms', 'popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'years']\n",
    "features_set_oriented = ['artists_ids']\n",
    "\n",
    "features = [] \n",
    "features.extend(features_categorical)\n",
    "features.extend(features_numerical)\n",
    "features.extend(features_set_oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only to ensure correct type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[features_numerical] = tracks_df[features_numerical].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the metrics proposed. For now, I normalize the numerical data, ensuring the range to be $[0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tracks_df[features_numerical] = scaler.fit_transform(tracks_df[features_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categorical = lambda x1,x2: x1 == x2\n",
    "metric_set_oriented = lambda x1, x2: len(set(x1) & set(x2))/(max(len(x1), len(x2)))\n",
    "metric_numerical = lambda x1, x2: 1 - abs(x1 - x2)\n",
    "\n",
    "def metric_songs(x: np.array, y: np.array) -> float: \n",
    "    # Arbitrary choice \n",
    "    weight = np.ones(19)/19\n",
    "    \n",
    "    similarity = 0\n",
    "    similarity += sum(weight[0:6]*metric_categorical(x[0:6], y[0:6]))\n",
    "    similarity += sum(weight[6:18]*metric_numerical(x[6:18], y[6:18]))\n",
    "    similarity += weight[18]*metric_set_oriented(x[18], y[18])\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example :\n",
    "\n",
    "\n",
    "Let's calculate a simple case with two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8309429212833058"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array(tracks_df[features].iloc[10])\n",
    "x2 = np.array(tracks_df[features].iloc[34])\n",
    "metric_songs(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Similarity Matrix\n",
    "\n",
    "I use the pdist function to calculate distance between tracks. I sample only 2 thousand song, because it can take a long time to run the comparision between all songs. After I can convert this similarity matrix to a distance matrix if I wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks_selected = tracks_df.sample(2000, random_state = 1000)\n",
    "#tracks_similarity = pdist(tracks_selected[features].values, metric = metric_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_similarity = - lambda*np.log(lambda*tracks_similarity)\n",
    "#tracks_similarity = squareform(tracks_similarity) + np.eye(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (15,12))\n",
    "#heatmap(tracks_similarity, vmin = 0, vmax = tracks_similarity.max(), ax = ax)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterization Algorithms\n",
    "\n",
    "This algorithms require distance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AffinityPropagation(affinity = 'precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantos labels foram feitos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantas playlists realmente existiam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tracks.iloc[0:2000].playlist_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = DBSCAN(eps = 0.25, metric = 'precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(model2.labels_[model2.labels_ == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(model2.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3 = SpectralClustering(n_clusters=27, affinity='precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation based on similarity. \n",
    "\n",
    "I use the metric specified like a probability. That probability tell us which factor we should recommend a song. In special, we choose, iteratively, the music that optimizes the product of probabilities, related to the likelihood. \n",
    "\n",
    "#### Test\n",
    "\n",
    "I initialize with a random song and will take 10 songs to build a playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_songs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_similar_track(tracks_similarity: np.array) -> int: \n",
    "    \n",
    "    interest_tracks = tracks_similarity.prod(axis = 0)\n",
    "    song = np.argmax(interest_tracks)\n",
    "    \n",
    "    return song \n",
    "\n",
    "def get_playlist(number_of_songs: int, tracks: np.array, songs: list) -> list: \n",
    "    \n",
    "    assert initial_song < tracks.shape[0]\n",
    "    assert initial_song >= 0 \n",
    "    \n",
    "    n = len(songs)\n",
    "    \n",
    "    tracks_similarity = np.ones((number_of_songs + n, tracks.shape[0]))\n",
    "    \n",
    "    # calcugelate the similarity between track in the playlist\n",
    "    tracks_similarity[0:n-1,:] = cdist(tracks[songs[:-1],:], tracks, metric = metric_songs)\n",
    "    \n",
    "    for s in range(n-1): \n",
    "        tracks_similarity[s,songs[s]] = 0\n",
    "    \n",
    "    for playlist_item in range(n-1, number_of_songs + n-1):\n",
    "\n",
    "        tracks_similarity[playlist_item,:] = cdist(tracks[songs[len(songs)-1:],:], tracks, metric = metric_songs) \n",
    "        \n",
    "        # Setting it to 0 take the used music to 0\n",
    "        tracks_similarity[playlist_item, songs[-1]] = 0\n",
    "        \n",
    "        songs.append(get_similar_track(tracks_similarity))\n",
    "    \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_drop = tracks_df.drop_duplicates('id', ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_test = tracks_df.sample()['playlist_id'].iloc[0]\n",
    "playlist_tracks = tracks_df[tracks_df['playlist_id'] == playlist_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = list(tracks_df_drop[tracks_df_drop['id'].isin(tracks_df.loc[playlist_tracks.index]['id'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-487ef38e080b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselected_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplaylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_playlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks_df_drop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msongs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-d1bb9377f6a8>\u001b[0m in \u001b[0;36mget_playlist\u001b[0;34m(number_of_songs, tracks, songs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# calcugelate the similarity between track in the playlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtracks_similarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/espotifai/lib/python3.8/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m                 \u001b[0mdm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-cceb8553e3c2>\u001b[0m in \u001b[0;36mmetric_songs\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msimilarity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmetric_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msimilarity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmetric_numerical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msimilarity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmetric_set_oriented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-cceb8553e3c2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetric_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetric_set_oriented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetric_numerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmetric_songs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "selected_songs = np.random.choice(songs, 50, replace = False)\n",
    "playlist = get_playlist(20, tracks_df_drop[features].values, selected_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (espotifai)",
   "language": "python",
   "name": "espotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
