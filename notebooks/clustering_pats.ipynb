{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## Based on the article [PATS](http://ismir2002.ircam.fr/proceedings/OKPROC02-FP07-4.pdf)\n",
    "\n",
    "The ideia is to establish a similarity metric and do a clusterization process with these metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist, squareform\n",
    "\n",
    "from seaborn import heatmap \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Important Features \n",
    "\n",
    "This features will be used to understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =  ['playlist_id', 'duration_ms', 'explicit', 'id', 'album_type', 'popularity', 'album_id', \n",
    "             'album_release_date', 'artists_ids', 'name', 'artists_names']\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'key', 'mode', 'speechiness', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist and tracks dataframes \n",
    "\n",
    "Getting the data generated by Spotify API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_pickle('../data/sp_playlists.pkl')[['id']]\n",
    "playlists_df['playlist_id'] = playlists_df['id']\n",
    "playlists_df = playlists_df[['playlist_id']]\n",
    "audio_features_df = pd.read_pickle('../data/sp_audio_features.pkl')[audio_features]\n",
    "tracks_df = pd.concat(\n",
    "    [pd.read_pickle(file)[metadata] for file in glob.glob('../data/sp_tracks_ready_*.pkl')],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = audio_features_df.merge(tracks_df, on = 'id')\n",
    "tracks_df = tracks_df.merge(playlists_df, on = 'playlist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del audio_features_df\n",
    "del playlists_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the dates to datetime and use the year as a continuum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>album_type</th>\n",
       "      <th>popularity</th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_release_date</th>\n",
       "      <th>artists_ids</th>\n",
       "      <th>name</th>\n",
       "      <th>artists_names</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273121</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.615</td>\n",
       "      <td>-11.941</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.233</td>\n",
       "      <td>...</td>\n",
       "      <td>254106.0</td>\n",
       "      <td>False</td>\n",
       "      <td>album</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2HVx2tiZnLX8xeaUthed1e</td>\n",
       "      <td>1976-09-28</td>\n",
       "      <td>[7guDJrEfX3qb6FEbdPA5qi]</td>\n",
       "      <td>Summer Soft</td>\n",
       "      <td>[Stevie Wonder]</td>\n",
       "      <td>1976.826712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        danceability  energy  loudness  key  mode  speechiness  acousticness  \\\n",
       "273121         0.552   0.615   -11.941   11     1       0.0605         0.417   \n",
       "\n",
       "        instrumentalness  liveness  valence  ...  duration_ms  explicit  \\\n",
       "273121          0.000113     0.106    0.233  ...     254106.0     False   \n",
       "\n",
       "       album_type popularity                album_id album_release_date  \\\n",
       "273121      album        0.0  2HVx2tiZnLX8xeaUthed1e         1976-09-28   \n",
       "\n",
       "                     artists_ids         name    artists_names        years  \n",
       "273121  [7guDJrEfX3qb6FEbdPA5qi]  Summer Soft  [Stevie Wonder]  1976.826712  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df['album_release_date'] = tracks_df['album_release_date'].apply(lambda x: \n",
    "                                                                        None if x == '0000' else pd.to_datetime(x))\n",
    "tracks_df['years'] = tracks_df['album_release_date'].apply(lambda x: x.year + x.month/12 + x.day/365)\n",
    "tracks_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45 nan values in the years columns. I will put the mean of the values, because it's few missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['years'].fillna(np.mean(tracks_df['years']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separate the catefortical, numerical and set_oriented features, to make the ideia of the similarity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical =  ['explicit', 'album_type', 'album_id', 'key', 'mode', 'time_signature']\n",
    "features_numerical = ['duration_ms', 'popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'years']\n",
    "features_set_oriented = ['artists_ids']\n",
    "\n",
    "features = [] \n",
    "features.extend(features_categorical)\n",
    "features.extend(features_numerical)\n",
    "features.extend(features_set_oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only to ensure correct type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[features_numerical] = tracks_df[features_numerical].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the metrics proposed. For now, I normalize the numerical data, ensuring the range to be $[0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tracks_df[features_numerical] = scaler.fit_transform(tracks_df[features_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categorical = lambda x1,x2: x1 == x2\n",
    "metric_set_oriented = lambda x1, x2: len(set(x1) & set(x2))/(max(len(x1), len(x2)))\n",
    "metric_numerical = lambda x1, x2: 1 - abs(x1 - x2)\n",
    "\n",
    "def metric_songs(x: np.array, y: np.array) -> float: \n",
    "    # Arbitrary choice \n",
    "    weight = np.ones(19)/19\n",
    "    \n",
    "    similarity = 0\n",
    "    similarity += sum(weight[0:6]*metric_categorical(x[0:6], y[0:6]))\n",
    "    similarity += sum(weight[6:18]*metric_numerical(x[6:18], y[6:18]))\n",
    "    similarity += weight[18]*metric_set_oriented(x[18], y[18])\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example :\n",
    "\n",
    "\n",
    "Let's calculate a simple case with two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8309429212833058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array(tracks_df[features].iloc[10])\n",
    "x2 = np.array(tracks_df[features].iloc[34])\n",
    "metric_songs(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Similarity Matrix\n",
    "\n",
    "I use the pdist function to calculate distance between tracks. I sample only 2 thousand song, because it can take a long time to run the comparision between all songs. After I can convert this similarity matrix to a distance matrix if I wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks_selected = tracks_df.sample(2000, random_state = 1000)\n",
    "#tracks_similarity = pdist(tracks_selected[features].values, metric = metric_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_similarity = - lambda*np.log(lambda*tracks_similarity)\n",
    "#tracks_similarity = squareform(tracks_similarity) + np.eye(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (15,12))\n",
    "#heatmap(tracks_similarity, vmin = 0, vmax = tracks_similarity.max(), ax = ax)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterization Algorithms\n",
    "\n",
    "This algorithms require distance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AffinityPropagation(affinity = 'precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantos labels foram feitos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantas playlists realmente existiam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tracks.iloc[0:2000].playlist_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = DBSCAN(eps = 0.25, metric = 'precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(model2.labels_[model2.labels_ == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(np.unique(model2.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3 = SpectralClustering(n_clusters=27, affinity='precomputed').fit(tracks_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation based on similarity. \n",
    "\n",
    "I use the metric specified like a probability. That probability tell us which factor we should recommend a song. In special, we choose, iteratively, the music that optimizes the product of probabilities, related to the likelihood. \n",
    "\n",
    "#### Test\n",
    "\n",
    "I initialize with a random song and will take 10 songs to build a playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_songs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def get_similar_track(tracks_similarity: np.array) -> int: \n",
    "    \n",
    "    interest_tracks = tracks_similarity.prod(axis = 0)\n",
    "    song = np.argmax(interest_tracks)\n",
    "    \n",
    "    return song \n",
    "\n",
    "def get_playlist(number_of_songs: int, tracks: np.array, songs: list) -> list: \n",
    "    \n",
    "    n = len(songs)\n",
    "    \n",
    "    tracks_similarity = np.ones((number_of_songs + n, tracks.shape[0]))\n",
    "    \n",
    "    # calculate the similarity between track in the playlist\n",
    "    tracks_similarity[0:n-1,:] = cdist(tracks[songs[:-1],:], tracks, metric = metric_songs)\n",
    "    \n",
    "    for s in range(n-1): \n",
    "        tracks_similarity[s,songs[s]] = 0\n",
    "    \n",
    "    for playlist_item in tqdm(range(n-1, number_of_songs + n-1)):\n",
    "\n",
    "        tracks_similarity[playlist_item,:] = cdist(tracks[songs[len(songs)-1:],:], tracks, metric = metric_songs) \n",
    "        \n",
    "        # Setting it to 0 take the used music to 0\n",
    "        tracks_similarity[playlist_item, songs[-1]] = 0\n",
    "        \n",
    "        songs.append(get_similar_track(tracks_similarity))\n",
    "    \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_drop = tracks_df.drop_duplicates('id', ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_test = tracks_df.sample()['playlist_id'].iloc[0]\n",
    "playlist_tracks = tracks_df[tracks_df['playlist_id'] == playlist_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = list(tracks_df_drop[tracks_df_drop['id'].isin(tracks_df.loc[playlist_tracks.index]['id'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec1b4ce0d3b4386a1d2c6b75cef716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_songs = list(np.random.choice(songs, 50, replace = False))\n",
    "playlist = get_playlist(20, tracks_df_drop[features].values, selected_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id_songs = set(tracks_df_drop.iloc[playlist].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No song from the playlist was achieved! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(playlist_tracks.id) & playlist_id_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (espotifai)",
   "language": "python",
   "name": "espotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
