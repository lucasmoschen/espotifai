{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Spotify dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Spotify playlists dataset based on a list of Last.fm users.\n",
    "\n",
    "We will do this way because it's not easy to gather Spotify users directly, but many Last.fm users are Spotify users too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import spotipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many users do we want to search for playlists?\n",
    "LEN_USERS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will gather Last.fm users and test if they are Spotify users too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/users.txt') as f:\n",
    "    users = f.read().split('\\n')\n",
    "    \n",
    "random.shuffle(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test users and obtain playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the users and gather their playlists at the same time, if it succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp_users = []\n",
    "playlists = []\n",
    "pbar = tqdm(total=LEN_USERS)\n",
    "for i, user in enumerate(users):\n",
    "    try:\n",
    "        their_playlists = sp.user_playlists(user)\n",
    "        playlists.extend(their_playlists['items'])\n",
    "        while their_playlists['next']:\n",
    "            their_playlists = sp.next(their_playlists)\n",
    "            playlists.extend(their_playlists['items'])\n",
    "    except:\n",
    "        continue\n",
    "    pbar.update()\n",
    "    sp_users.append(user)\n",
    "    if (i + 1) % 100 == 0:\n",
    "        time.sleep(5)\n",
    "    if len(sp_users) >= LEN_USERS:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have now {} playlists!'.format(len(playlists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Spotify users to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/sp_users.txt', 'w') as f:\n",
    "    for user in sp_users:\n",
    "        f.write('{}\\n'.format(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: get number of followers info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be necessary to pass again through all playlists just for a bit of information, that is, the number of followers of a playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, playlist in tqdm(enumerate(playlists.copy()), total=len(playlists.copy())):\n",
    "#     playlists[i] = sp.playlist(playlists[i]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat playlists dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we treat the dataset playlists, filtering just what we want. We also expand the `owner` column and remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns\n",
    "playlists = pd.DataFrame(playlists, columns=[\n",
    "    'collaborative',\n",
    "    'description',\n",
    "#     'external_urls',\n",
    "#     'followers',\n",
    "#     'href',\n",
    "    'id',\n",
    "#     'images',\n",
    "    'name',\n",
    "    'owner',\n",
    "    'primary_color',\n",
    "    'public',\n",
    "#     'snapshot_id',\n",
    "    'tracks',\n",
    "#     'type',\n",
    "#     'uri'\n",
    "])\n",
    "\n",
    "# Expand owner dict\n",
    "playlists['owner_id'] = playlists['owner'].apply(pd.Series)['id']\n",
    "playlists.drop(columns='owner', inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "playlists.drop_duplicates('id', inplace=True)\n",
    "\n",
    "# Reindex\n",
    "playlists.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write playlists dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists.to_csv('../../data/sp_playlists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through playlists to get tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate through the playlists dataset in order to gather information about tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion\n",
    "playlists = playlists.to_dict('records')\n",
    "\n",
    "# Iteration\n",
    "tracks = []\n",
    "for i, playlist in tqdm(enumerate(playlists), total=len(playlists)):\n",
    "    q = sp.playlist_tracks(playlist['id'])\n",
    "    items = q['items'].copy()\n",
    "    for item in items:\n",
    "        item.update({'playlist_id': playlist['id']})\n",
    "    tracks.extend(items)\n",
    "    while q['next']:\n",
    "        q = sp.next(q)\n",
    "        items = q['items'].copy()\n",
    "        for item in items:\n",
    "            item.update({'playlist_id': playlist['id']})\n",
    "        tracks.extend(items)\n",
    "    if (i + 1) % 100 == 0:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat tracks database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "df = pd.DataFrame(tracks, columns=[\n",
    "    'added_at',\n",
    "    'added_by',\n",
    "    'is_local',\n",
    "#     'primary_color',\n",
    "    'track',\n",
    "#     'video_thumbnail',\n",
    "    'playlist_id',\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "print('{} rows were dropped.'.format(len(df.drop(df.dropna().index))))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates\n",
    "df.added_at = pd.to_datetime(df.added_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand added_by column\n",
    "df['added_by'] = df.added_by.apply(pd.Series).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand track column\n",
    "\n",
    "df2 = df.track.apply(pd.Series).copy()\n",
    "df2 = df2[[\n",
    "    'album',\n",
    "    'artists',\n",
    "    'available_markets',\n",
    "    'disc_number',\n",
    "    'duration_ms',\n",
    "#     'episode',\n",
    "    'explicit',\n",
    "#     'external_ids',\n",
    "#     'external_urls',\n",
    "#     'href',\n",
    "    'id',\n",
    "#     'is_local',\n",
    "    'name',\n",
    "    'popularity',\n",
    "#     'preview_url',\n",
    "#     'track',\n",
    "    'track_number',\n",
    "#     'type',\n",
    "#     'uri',\n",
    "#     'linked_from'\n",
    "]]\n",
    "df = df.join(df2)\n",
    "df.drop(columns='track', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand album column\n",
    "\n",
    "df2 = df.album.apply(pd.Series).copy()\n",
    "df2 = df2[[\n",
    "    'album_type',\n",
    "    'artists',\n",
    "    'available_markets',\n",
    "#     'external_urls',\n",
    "#     'href',\n",
    "    'id',\n",
    "#     'images',\n",
    "    'name',\n",
    "    'release_date',\n",
    "#     'release_date_precision',\n",
    "#     'total_tracks',\n",
    "#     'type',\n",
    "#     'uri'\n",
    "]]\n",
    "df2.rename(columns={\n",
    "    'artists': 'album_artists',\n",
    "    'available_markets': 'album_available_markets',\n",
    "    'id': 'album_id',\n",
    "    'name': 'album_name',\n",
    "    'release_date': 'album_release_date'\n",
    "}, inplace=True)\n",
    "df = df.join(df2)\n",
    "df.drop(columns='album', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand artists column\n",
    "\n",
    "df['artists_ids'] = df.artists.apply(lambda x: [i['id'] for i in x])\n",
    "df['artists_names'] = df.artists.apply(lambda x: [i['name'] for i in x])\n",
    "df.drop(columns='artists', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand album_artists column\n",
    "\n",
    "df['album_artists_ids'] = df.album_artists.apply(lambda x: [i['id'] for i in x])\n",
    "df['album_artists_names'] = df.album_artists.apply(lambda x: [i['name'] for i in x])\n",
    "df.drop(columns='album_artists', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "print('{} rows were dropped.'.format(len(df.drop(df.dropna().index))))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write tracks database to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/pd_tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through tracks to get their features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracks have features, like `danceability`, which is important for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = []\n",
    "\n",
    "for i in tqdm(range(0, len(df), 100)):\n",
    "    q = sp.audio_features(df.id.to_list()[i:i+100])\n",
    "    audio_features.extend(q)\n",
    "    if i % 10000 == 0:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sp.audio_features` can return `[None]`, so we check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices where audio_features is None\n",
    "none_indices = [i for i in range(len(audio_features)) if audio_features[i] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop them in both df and audio_features\n",
    "df.drop(index=none_indices, inplace=True)\n",
    "for index in none_indices[::-1]:\n",
    "    del audio_features[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = pd.DataFrame(audio_features, columns=[\n",
    "    'danceability',\n",
    "    'energy',\n",
    "    'key',\n",
    "    'loudness',\n",
    "    'mode',\n",
    "    'speechiness',\n",
    "    'acousticness',\n",
    "    'instrumentalness',\n",
    "    'liveness',\n",
    "    'valence',\n",
    "    'tempo',\n",
    "#     'type',\n",
    "#     'id',\n",
    "#     'uri',\n",
    "#     'track_href',\n",
    "#     'analysis_url',\n",
    "#     'duration_ms',\n",
    "    'time_signature'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(audio_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write final dataset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/sp_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
