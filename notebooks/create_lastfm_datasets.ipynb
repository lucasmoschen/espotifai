{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lastfm API with pyLast\n",
    "\n",
    "This repository aims to create the datasets based on lastfm API. The functions are written in ```create_last_database.py``` and ```generate_lastfm_users.py```.\n",
    "\n",
    "This are the main references to follow: \n",
    "\n",
    "- [Oficial Website](https://www.last.fm/api/)\n",
    "\n",
    "- [PyLast Repo](https://github.com/pylast)\n",
    "\n",
    "To create the datasets, it's necessary yo have an account on Last.fm and to create an Application, in order to obtain an ```api_key``` and ```api_key_secret```. \n",
    "\n",
    "**You do not need to generate all data for the analysis. This is a secondary data source and because of the slowness to get data from LAST.FM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pylast\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import requests\n",
    "import time \n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../../scripts/') \n",
    "\n",
    "from create_last_database import User\n",
    "from create_last_database import Track\n",
    "from create_last_database import Artist\n",
    "from create_last_database import Album\n",
    "from create_last_database import Tag\n",
    "from create_last_database import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network with the API through PyLast\n",
    "\n",
    "It connects to the API using PyLast library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = input()\n",
    "API_SECRET = input()\n",
    "\n",
    "network = pylast.LastFMNetwork(api_key=API_KEY, api_secret=API_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Users\n",
    "\n",
    "Let's get some random users built by `generate_lastfm_users.py`. I use `random_state` to keep reproducibility. The original dataset has more than 30 thousand users. To generate that list of usernames, I visited the Last.fm webpage of several artists. But I considered three users randomly iin the top listenings from three different coutries: Brazil, USA and United Kingdom. Using just this username, I generated additional Last.fm usernames using the user.getFriends method. With some loops, we can get the network (or part of it). It's possible to have some bias unknown yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_users(filepath: str, quantity: int = 1000, random_state: int = 200) -> pd.DataFrame:\n",
    "    \n",
    "    users = pd.read_csv(filepath)\n",
    "    chosen_users = users.sample(n = quantity, replace = False, random_state = random_state, axis = 'index')\n",
    "    chosen_users.index = list(range(0,len(chosen_users)))\n",
    "\n",
    "    return chosen_users\n",
    "\n",
    "user_path = \"../../data/lastfm-api/users_lastfm.csv\"\n",
    "\n",
    "users = get_random_users(user_path)\n",
    "users.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the database \n",
    "\n",
    "It takes a long, long time (really, really long). For each infomation, I have to request four or five links, to extract the information. Some problems with **MalResponse**, **Network** and **Connection** are expected. For some especial cases, I just rerun the cell. \n",
    "\n",
    "Remember: It takes a really big time. That's why it won't be the main dataset (for users 15s in mean for each user)!\n",
    "\n",
    "We start with the users info. All the following information is saved in a json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '../../data/lastfm-api/'\n",
    "\n",
    "users_class = User(network, user_path)\n",
    "\n",
    "file_user_name = '2k_users_info_lastfm.json'\n",
    "\n",
    "MAX_USERS = 1000\n",
    "\n",
    "if not os.path.exists(FOLDER_PATH):\n",
    "    os.mkdir(FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle the file \n",
    "if not os.path.exists(os.path.join(FOLDER_PATH, file_user_name)):\n",
    "    with open(os.path.join(FOLDER_PATH, file_user_name), 'w') as f:\n",
    "        json.dump({}, f)\n",
    "with open(os.path.join(FOLDER_PATH, file_user_name), 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "t0 = time.time()\n",
    "for i, user in users.iterrows():\n",
    "    if i > MAX_USERS: \n",
    "        break\n",
    "    # If the user is in the file already, continue\n",
    "    if str(user.user_id) in data:\n",
    "        continue\n",
    "    with open(os.path.join(FOLDER_PATH, file_user_name), 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        # A lot of internet problems may occur.\n",
    "        while True: \n",
    "            try: \n",
    "                user_info = users_class.get_user_info(user.user_name)\n",
    "            except pylast.NetworkError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            except pylast.MalformedResponseError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        # We save the information in a json format (as a dictionary)\n",
    "        data[user.user_id] = user_info\n",
    "        f.seek(0)\n",
    "        json.dump(data, f)\n",
    "        if len(data) % 10 == 0:\n",
    "            clear_output()\n",
    "            print('{} users - DONE: {} seconds'.format(len(data), (time.time() - t0)))\n",
    "            t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `tracks.csv` file, I will build the tracks dataset. It may take long time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_class = Track(network)\n",
    "MAX_TRACKS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle the filename\n",
    "if not os.path.exists(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json')):\n",
    "    with open(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json'), 'w') as f:\n",
    "        json.dump({}, f)\n",
    "with open(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json'), 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "t0 = time.time()\n",
    "for track_id, data_track in track_class.tracks_df.iterrows():\n",
    "    if track_id > MAX_TRACKS: \n",
    "        break\n",
    "    if str(track_id) in data:\n",
    "        continue\n",
    "    with open(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json'), 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        while True:\n",
    "            try: \n",
    "                track_info = track_class.get_track_info(data_track.track_name, data_track.artist_name)\n",
    "            except pylast.NetworkError:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            except pylast.MalformedResponseError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            break\n",
    "            \n",
    "        # We save the information in a json format (as a dictionary)    \n",
    "        data[track_id] = track_info\n",
    "        f.seek(0)\n",
    "        json.dump(data, f)\n",
    "        if len(data) % 10 == 0:\n",
    "            clear_output()\n",
    "            print('{} tracks - DONE: {} seconds'.format(len(data), (time.time() - t0)))\n",
    "            t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the artist database. The principle is the same for the last one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_class = Artist(network)\n",
    "MAX_ARTISTS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json')):\n",
    "    with open(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json'), 'w') as f:\n",
    "        json.dump({}, f)\n",
    "with open(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json'), 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "t0 = time.time()\n",
    "for artist_id, data_artist in artist_class.artists_df.iterrows():\n",
    "    if artist_id > MAX_ARTISTS:\n",
    "        break\n",
    "    if str(artist_id) in data:\n",
    "        continue\n",
    "    with open(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json'), 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        while True:\n",
    "            try: \n",
    "                artist_info = artist_class.get_artist_info(data_artist.artist_name)\n",
    "            except pylast.NetworkError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            except pylast.MalformedResponseError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            break\n",
    "        data[artist_id] = artist_info\n",
    "        f.seek(0)\n",
    "        json.dump(data, f)\n",
    "        if len(data) % 10 == 0:\n",
    "            clear_output()\n",
    "            print('{} artists - DONE: {} seconds'.format(len(data), (time.time() - t0)))\n",
    "            t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the dabase for the tags. The principle is the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_class = Tag(network)\n",
    "MAX_TAGS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(FOLDER_PATH, 'tags_lastfm_info.json')):\n",
    "    with open(os.path.join(FOLDER_PATH, 'tags_lastfm_info.json'), 'w') as f:\n",
    "        json.dump({}, f)\n",
    "with open(os.path.join(FOLDER_PATH, 'tags_lastfm_info.json'), 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "t0 = time.time()\n",
    "for tag_id, data_tag in tag_class.tags_df.iterrows():\n",
    "    if tag_id > MAX_TAGS: \n",
    "        break\n",
    "    if str(tag_id) in data:\n",
    "        continue\n",
    "    with open(os.path.join(FOLDER_PATH, 'tags_lastfm_info.json'), 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        while True:\n",
    "            try: \n",
    "                tag_info = tag_class.get_tag_info(data_tag.tag)\n",
    "            except pylast.NetworkError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            except pylast.MalformedResponseError as e:\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            break\n",
    "        data[tag_id] = tag_info\n",
    "        f.seek(0)\n",
    "        json.dump(data, f)\n",
    "        if len(data) % 10 == 0:\n",
    "            clear_output()\n",
    "            print('{} tags - DONE: {} seconds'.format(len(data), (time.time() - t0)))\n",
    "            t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting similar tracks in track info to index. I separate of the original code cause it was lazy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "track_class = Track(network)\n",
    "\n",
    "with open(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json'), 'r+') as f:\n",
    "    data = json.load(f)\n",
    "for index_ex, key in enumerate(data.keys()):\n",
    "    if len(data[key]) == 0: \n",
    "        continue\n",
    "    for index, info in enumerate(data[key]['similar']): \n",
    "        data[key]['similar'][index] = [track_class.get_id_by_name(info[0], info[1]), info[2]]\n",
    "    if index_ex % 100 == 0: \n",
    "        clear_output()\n",
    "        print(\"{} - DONE\".format(index_ex))\n",
    "\n",
    "with open(os.path.join(FOLDER_PATH, 'tracks_lastfm_info.json'), 'w') as f: \n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json'), 'r+') as f:\n",
    "    data = json.load(f)\n",
    "for key in data.keys():\n",
    "    if len(data[key]) == 0: \n",
    "        continue\n",
    "    for index, info in enumerate(data[key]['similar']): \n",
    "        data[key]['similar'][index] = [artist_class.get_id_by_name(info[0]), info[1]]\n",
    "\n",
    "with open(os.path.join(FOLDER_PATH, 'artists_lastfm_info.json'), 'w') as f: \n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writting the new artists and tracks (**Remember to run this cell**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_class.write_to_csv()\n",
    "track_class.write_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a Library for 50 users\n",
    "\n",
    "For each user, we get all the artists returned from its library. It's expected some errors when importing these data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_library = Library(network)\n",
    "limit = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(FOLDER_PATH, 'users50_library.json')):\n",
    "    with open(os.path.join(FOLDER_PATH, 'users50_library.json'), 'w') as f:\n",
    "        json.dump({}, f)\n",
    "with open(os.path.join(FOLDER_PATH, 'users50_library.json'), 'r') as f:\n",
    "    users50_library = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, user in users.iterrows():\n",
    "    if i >= limit: break\n",
    "    if str(user['user_id']) in users50_library:\n",
    "        continue\n",
    "    print(user['user_id'])\n",
    "    # If printing = True, you get information about each page. \n",
    "    user_library = artist_library.get_library(user['user_name'], printing=False)\n",
    "    users50_library[user['user_id']] = user_library\n",
    "    clear_output()\n",
    "    print('{} - DONE'.format(user['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FOLDER_PATH, 'users50_library.json'), 'w') as f:\n",
    "    json.dump(users50_library, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
