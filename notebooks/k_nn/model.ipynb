{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a playlist, we want to add more tracks: it's the **playlist continuation** problem. Following [Kelen et al.](https://dl.acm.org/doi/abs/10.1145/3267471.3267477), the idea here is to define a similarity metric between two playlists, select the $k$ most similar playlists to ours, define a score metric for tracks continuing our playlist and choose the best tracks to continue it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "\n",
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load and treat the tracks dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracks_dfs():\n",
    "    for file in glob.glob('../../data/sp_tracks_ready_*.pkl'):\n",
    "        df = pd.read_pickle(file)[['id', 'playlist_id', 'artists_ids']]\n",
    "        yield pd.concat([df, pd.DataFrame({'file': [file]*len(df)})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b028721e5cc542328f7d9bd9323784e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_df = pd.concat(tqdm(tracks_dfs(), total=128), ignore_index=True)\n",
    "tracks_df.dropna(inplace=True)\n",
    "\n",
    "# The following is necessary to discard repeated playlists\n",
    "tracks_df['idx'] = tracks_df.index\n",
    "grouped = tracks_df.groupby(['playlist_id', 'file'])['idx'].apply(list).reset_index()\n",
    "tracks_df = tracks_df.drop(index = [el for list in grouped[grouped.duplicated('playlist_id')].idx for el in list])\n",
    "del grouped\n",
    "tracks_df.drop(columns='idx', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We treat the playlists dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = tracks_df.groupby('playlist_id')['id'].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We treat the artists for each track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = tracks_df.drop_duplicates('id').set_index('id').artists_ids\n",
    "artists.index.name = 'track_id'\n",
    "artists_ids = dict(zip(artists.index, range(len(artists))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only playlists between 5 and 250 tracks\n",
    "query = playlists.apply(lambda x: len(x))\n",
    "playlists = playlists[(query >= 5) & (query <= 250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test data\n",
    "n_test = int(np.ceil(len(playlists)*0.2))\n",
    "query = playlists.apply(lambda x: len(x))\n",
    "playlists_test = playlists[(query > 25)].sample(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_training = playlists.drop(index = playlists_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance matrix $R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the relevance matrix $R$.\n",
    "\n",
    "$R_{ij}=r_{ij}$ indicates if a track $j$ is relevant to the playlist $i$, that is, the track is in the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270c960bd64f41d0bad96e18da473246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_tracks = []\n",
    "for playlist in tqdm(playlists_training.to_list()):\n",
    "    all_tracks.extend(playlist)\n",
    "all_tracks = list(set(all_tracks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will use matrix multiplication, we have to index each track and each playlist id to index of the matrix. We do it here using dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids_go = dict(zip(all_tracks, range(len(all_tracks))))\n",
    "track_ids_back = dict(zip(track_ids_go.values(), track_ids_go.keys()))\n",
    "playlist_ids = dict(zip(set(playlists_training.index), range(len(set(playlists_training.index)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bee779d70e41bbaca0c3cc6cafe347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = len(set(playlists_training.index))\n",
    "n = len(set(all_tracks))\n",
    "R = lil_matrix((m, n))\n",
    "\n",
    "for playlist_id, playlist in tqdm(playlists_training.iteritems(), total=len(playlists_training)):\n",
    "    for track_id in playlist:\n",
    "        R[playlist_ids[playlist_id], track_ids_go[track_id]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between two playlists $u$ and $v$ is calculated by:\n",
    "$$s_{uv} = \\sum_{i \\in I} \\dfrac{r_{ui}r_{vi}}{||R_u||_2||R_v||_2}$$\n",
    "$I$ is the set of tracks and $R_u$ is the vector of relevances $r_{ui}$ for the playlist $u$.\n",
    "\n",
    "In fact, we basically count the number of tracks in the intersection of the playlists and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(playlist_1, playlist_2):\n",
    "    \"\"\"Calculate the similarity between two playlists.\"\"\"\n",
    "    summation = len(set(playlist_1) & set(playlist_2))\n",
    "    return summation/(np.sqrt(len(playlist_1))*np.sqrt(len(playlist_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a playlist $u$ to be continuated, we calculate the similarity of it with all existent playlists and select the $k$ most similar playlists, that is, the set $N_k(u)$. So, we define a score for a track to be in the playlist:\n",
    "$$\\hat{r}_{ui} = \\dfrac{\\sum_{v \\in N_k(u)} s_{uv} \\cdot r_{vi}}{\\sum_{v \\in N_k(u)} s_{uv}}$$\n",
    "\n",
    "The intuition is that we are giving high scores to tracks that are in many playlists with great similarities to out playlist. We return the tracks ordered by score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuation(playlist, k):\n",
    "    \"\"\"Continue a playlist based on k most similar playlists.\"\"\"\n",
    "    s_u = lil_matrix((1, m))\n",
    "    for alt_playlist_index, alt_playlist in playlists_training.items():\n",
    "        s_u[0, playlist_ids[alt_playlist_index]] = similarity(playlist, alt_playlist)\n",
    "    sorted_similarities_indices = np.flip(np.argsort(s_u.toarray()[0]))\n",
    "    top_k_similarities_indices = sorted_similarities_indices[:k]\n",
    "    scores = (s_u[0, top_k_similarities_indices]*R[top_k_similarities_indices, :]).toarray()[0]\n",
    "    sorted_scores_indices = np.flip(np.argsort(scores)[-500:])\n",
    "    return [track_ids_back[index] for index in sorted_scores_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-precision metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in their work, [Chen et al.](https://dl.acm.org/doi/10.1145/3240323.3240342) suggest a metric for playlist continuation evaluation. They call it **R-precision**. It measures how many of the real tracks (and their artists) the model suggested correctly.\n",
    "\n",
    "A playlist as input to the model has two parts: its part on display to the model and it's hidden part. The hidden part is what the model try to predict and is called *ground truth*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{R-precision} = \\dfrac{|S_T \\cap G_T| + 0.25 \\cdot |S_A \\cap G_A|}{|G_T|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$G_T$ is the set of unique track IDs from ground truth, that is, the unique hidden tracks. $S_T$ is the suggested tracks from our model. $G_A$ is the set of unique artists IDs from ground truth and $S_A$ is the set of predicted artists. The metric can be interpreted as accuracy (although it can be greater than 1), but giving some score for wrong tracks with right artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(S_t, G_t, S_a, G_a):\n",
    "    return (len(set(S_t) & set(G_t)) + 0.25 * len(set(S_a) & set(G_a))) / len(G_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(playlist_not_hidden, playlist_hidden, continuation):\n",
    "    continuation = continuation.copy()\n",
    "    for track in set(playlist_not_hidden):\n",
    "        if track in continuation:\n",
    "            continuation.remove(track)\n",
    "    continuation = continuation[:len(playlist_hidden)]\n",
    "    \n",
    "    G_a = []\n",
    "    for track in playlist_hidden:\n",
    "        G_a.extend(artists.iloc[artists_ids[track]])\n",
    "    S_a = []\n",
    "    for track in continuation:\n",
    "        S_a.extend(artists.iloc[artists_ids[track]])\n",
    "        \n",
    "    metric = r_precision(continuation, playlist_hidden, S_a, G_a)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now select a $k$ value that maximizes the R-precision metric in our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7857ba2779bd4e68a86261ec6d21cc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ad50b1c5e4f528a010f5f6a02225a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=1, the R-precision for our model is about 0.059119349930770566.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94044be24c1345469eee1852daa778bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=5, the R-precision for our model is about 0.08112396859029525.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c9222438404d95833dc90cb679b07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=10, the R-precision for our model is about 0.09701821526056069.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f58761468d4d64b7e20e8c5c98801c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=1000, the R-precision for our model is about 0.10973446710248691.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68606bbe64840d895cd5d827e3dace9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=4000, the R-precision for our model is about 0.09078662201016692.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee489e67ad2149f0a4ac6f8302f04e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=10000, the R-precision for our model is about 0.10893415539611212.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7376b1ac3a97428788da688aced31e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With k=15241, the R-precision for our model is about 0.08637187650537527.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 1000, 4000, 10000, len(playlists_test)]):\n",
    "    sum_metric = 0\n",
    "    # sum_random = 0\n",
    "    for playlist in tqdm(playlists_test.sample(200)):\n",
    "        playlist_not_hidden = playlist[:25]\n",
    "        playlist_hidden = playlist[25:]\n",
    "        continuated = continuation(playlist_not_hidden, k)\n",
    "        metric = evaluation(playlist_not_hidden, playlist_hidden, continuated)\n",
    "    #     random_metric = evaluation(playlist_not_hidden, playlist_hidden, random.sample(all_tracks, 500))\n",
    "        sum_metric += metric\n",
    "    #     sum_random += random_metric\n",
    "    print('With k={}, the R-precision for our model is about {}.'.format(k, sum_metric/200))\n",
    "    # print('A random model performs {}.'.format(sum_random/len(playlists_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said by [Chen et al.](https://dl.acm.org/doi/10.1145/3240323.3240342), the highest performance achieved in *RecSys Challenge 2018* was 0.2241. Well, many competitors were using much more advanced models, like neural networks, and they also had much more data and possible more computational power. So the results we achieved seems much reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before evaluating out model, it's worth it to do a sanity check. We will take the most listened songs from The Beatles and continue the playlist, with $k = 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = sp.search('michael jackson', type='artist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our playlist to be continuated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Billie Jean',\n",
       " 'Beat It - Single Version',\n",
       " 'Smooth Criminal - 2012 Remaster',\n",
       " \"Don't Stop 'Til You Get Enough - Single Version\",\n",
       " 'Don’t Matter To Me (with Michael Jackson)',\n",
       " 'The Way You Make Me Feel - 2012 Remaster',\n",
       " 'Rock with You - Single Version',\n",
       " \"They Don't Care About Us\",\n",
       " 'P.Y.T. (Pretty Young Thing)',\n",
       " 'Remember the Time']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[track['name'] for track in sp.artist_top_tracks(q['artists']['items'][0]['id'])['tracks']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sp.artist_top_tracks(q['artists']['items'][0]['id'])['tracks']\n",
    "result = continuation([track['id'] for track in temp], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = sp.tracks(result[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Billie Jean', 'Michael Jackson'),\n",
       " ('Beat It - Single Version', 'Michael Jackson'),\n",
       " (\"Don't Stop 'Til You Get Enough - Single Version\", 'Michael Jackson'),\n",
       " ('P.Y.T. (Pretty Young Thing)', 'Michael Jackson'),\n",
       " ('Rock with You - Single Version', 'Michael Jackson'),\n",
       " ('Smooth Criminal - 2012 Remaster', 'Michael Jackson'),\n",
       " ('The Way You Make Me Feel - 2012 Remaster', 'Michael Jackson'),\n",
       " ('Remember the Time', 'Michael Jackson'),\n",
       " ('Bad - 2012 Remaster', 'Michael Jackson'),\n",
       " ('Take on Me', 'a-ha'),\n",
       " ('Thriller', 'Michael Jackson'),\n",
       " (\"They Don't Care About Us\", 'Michael Jackson'),\n",
       " ('Sweet Dreams (Are Made of This) - Remastered', 'Eurythmics'),\n",
       " ('Human Nature', 'Michael Jackson'),\n",
       " ('Man in the Mirror - 2012 Remaster', 'Michael Jackson'),\n",
       " ('Black or White', 'Michael Jackson'),\n",
       " (\"Wanna Be Startin' Somethin'\", 'Michael Jackson'),\n",
       " ('I Wanna Dance with Somebody (Who Loves Me)', 'Whitney Houston'),\n",
       " ('The Girl Is Mine', 'Michael Jackson'),\n",
       " ('Off the Wall', 'Michael Jackson'),\n",
       " ('Like a Virgin', 'Madonna'),\n",
       " ('Africa', 'TOTO'),\n",
       " ('Heal the World', 'Michael Jackson'),\n",
       " (\"I Just Can't Stop Loving You (feat. Siedah Garrett) - 2012 Remaster\",\n",
       "  'Michael Jackson'),\n",
       " ('Love Never Felt So Good', 'Michael Jackson')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(q['tracks'][i]['name'], q['tracks'][i]['artists'][0]['name']) for i in range(len(q['tracks']))][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it seems nice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
