{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Natrix\n",
    "\n",
    "## Based on the article [PATS](http://ismir2002.ircam.fr/proceedings/OKPROC02-FP07-4.pdf)\n",
    "\n",
    "The ideia is to establish a similarity metric and build a matrix to get playlists.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist, squareform, pdist\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seaborn import heatmap \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Important Features \n",
    "\n",
    "This features will be used to understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =  ['playlist_id', 'duration_ms', 'explicit', 'id', 'album_type', 'popularity', 'album_id', \n",
    "             'album_release_date', 'artists_ids', 'name', 'artists_names']\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'key', 'mode', 'speechiness', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist and tracks dataframes \n",
    "\n",
    "Getting the data generated by Spotify API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_pickle('../data/sp_playlists.pkl')[['owner_id', 'id', 'tracks']]\n",
    "playlists_df.rename(columns = {'id': 'playlist_id', 'tracks': 'n_tracks'}, inplace = True)\n",
    "\n",
    "playlists_df.n_tracks = playlists_df.n_tracks.apply(lambda x: x['total'])\n",
    "\n",
    "# Getting Playlists with at least 5 tracks and maximum of 500 tracks\n",
    "playlists_df = playlists_df[(playlists_df.n_tracks >= 5) & (playlists_df.n_tracks <= 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = pd.read_pickle('../data/sp_audio_features.pkl')[audio_features]\n",
    "tracks_df = pd.concat(\n",
    "    [pd.read_pickle(file)[metadata] for file in glob.glob('../data/sp_tracks_ready_*.pkl')],\n",
    "    ignore_index=True\n",
    ")\n",
    "tracks_df = audio_features_df.merge(tracks_df, on = 'id')\n",
    "del audio_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the dates to datetime and use the year as a continuum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['album_release_date'].replace(to_replace = '0000', value = None, inplace=True)\n",
    "tracks_df['album_release_date'] = pd.to_datetime(tracks_df['album_release_date'])\n",
    "tracks_df['album_release_date'] = (tracks_df['album_release_date'] - tracks_df['album_release_date'].min())\n",
    "tracks_df['days'] = tracks_df['album_release_date']/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45 nan values in the years columns. I will put the mean of the values, because it's few missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['days'].fillna(np.mean(tracks_df['days']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the artists to set, in order to follow the metric presented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.artists_ids = tracks_df.artists_ids.apply(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separate the catefortical, numerical and set_oriented features, to make the ideia of the similarity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical =  ['explicit', 'album_type', 'album_id', 'key', 'mode', 'time_signature']\n",
    "features_numerical = ['duration_ms', 'popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'days']\n",
    "features_set_oriented = ['artists_ids']\n",
    "\n",
    "features = [] \n",
    "features.extend(features_categorical)\n",
    "features.extend(features_numerical)\n",
    "features.extend(features_set_oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only to ensure correct type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[features_numerical] = tracks_df[features_numerical].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the metrics proposed. For now, I normalize the numerical data, ensuring the range to be $[0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tracks_df[features_numerical] = scaler.fit_transform(tracks_df[features_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categorical = lambda x1,x2:  x1 == x2\n",
    "metric_set_oriented = lambda x1, x2: len(x1 & x2)/(len(x1.union(x2)))\n",
    "metric_numerical = lambda x1, x2: 1 - abs(x1 - x2)\n",
    "\n",
    "# Ideia: I will give grades of importance (1 - 5) based on my experience to each feature. \n",
    "# Arbitrary choice\n",
    "weights = [1, 1, 5, 2, 3, 3, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 5]\n",
    "weights = np.array(weights)/sum(weights)\n",
    "\n",
    "def metric_songs(x: np.array, y: np.array) -> float: \n",
    "    \n",
    "    similarity = 0\n",
    "    similarity += np.dot(weights[0:6], metric_categorical(x[0:6], y[0:6]))\n",
    "    similarity += np.dot(weights[6:18], metric_numerical(x[6:18], y[6:18]))\n",
    "    similarity += weights[18]*metric_set_oriented(x[18], y[18])\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example :\n",
    "\n",
    "\n",
    "Let's calculate a simple case with two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6429353  0.67196831]\n",
      " [0.67909603 0.67121037]\n",
      " [0.71947156 0.67978537]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array(tracks_df[features].iloc[27:30])\n",
    "x2 = np.array(tracks_df[features].iloc[1003:1005])\n",
    "matrix = cdist(x1, x2, metric = metric_songs)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation based on similarity. \n",
    "\n",
    "We will use the metric described above. The similarity between two songs will be interpreted as a **probability**. We could build the role track similarity but it requires much computation. So I will do a simple modification. I will calculate the metric between two songs if they are in the same playlist, for some playlist in the dataset. I expect it reduces the number of calculations! After, we will have a sparser matrix and in order too add tracks to a playlist, we will add iteratively. With a list with n songs, we have the similarities with all tracks. It will be zero when the tracks aren't in the same playlist, for all playlists. We mutiply these probabilities for all tracks (it will be our likelihood) and maximeze it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "class SimilarityModel:\n",
    "    \n",
    "    def __init__(self, tracks: pd.DataFrame, playlists: pd.DataFrame): \n",
    "        '''Function with the implementation of the Simmilarity Model described above. \n",
    "           The metric used are describe in PATS article. \n",
    "           - tracks: all the tracks in your world. \n",
    "           - playlists: the training playlists.\n",
    "        '''\n",
    "        \n",
    "        self.tracks = tracks\n",
    "        self.playlists = playlists\n",
    "        # We will consider a dataframe with the unique tracks and create numerical indexes\n",
    "        self.tracks_index = self.tracks[['id']].drop_duplicates('id').reset_index()\n",
    "        # Let's watch the the rate of accuracy. We can confirm something after. \n",
    "        self.playlists['rate_of_hits'] = None\n",
    "        self.playlists = self.playlists.set_index('playlist_id')\n",
    "        \n",
    "    def get_similar_track(self, tracks_similarity: np.array) -> int: \n",
    "\n",
    "        # With this mask, we get only the columns with all lines having values\n",
    "        mask = tracks_similarity.getnnz(axis = 0) == tracks_similarity.shape[0]\n",
    "        interest_tracks = np.zeros(tracks_similarity.shape[1], dtype = float)\n",
    "        interest_tracks[mask] = np.prod(tracks_similarity[:,mask].A, axis = 0)\n",
    "        \n",
    "        song = np.argmax(interest_tracks)\n",
    "\n",
    "        return song \n",
    "    \n",
    "    def _get_index(self, tracks_ids):\n",
    "        \n",
    "        indexes = self.tracks_index[self.tracks_index.id.isin(tracks_ids)].index\n",
    "        \n",
    "        return list(indexes)\n",
    "    \n",
    "    def _get_track_number(self, index):\n",
    "        \n",
    "        track_id = self.tracks_index.loc[index]\n",
    "        return track_id.id\n",
    "    \n",
    "    def accuracy_metric(self, yhat, ytrue,n, j):\n",
    "\n",
    "        acc = (len(ytrue & yhat) - j)/(n - j)\n",
    "        return acc\n",
    "     \n",
    "    def fit(self): \n",
    "        '''This functions build the model with the tracks and playlists disposed. '''\n",
    "        \n",
    "        tracks_similarity = lil_matrix((len(self.tracks_index), len(self.tracks_index)), \n",
    "                                       dtype = float)\n",
    "        \n",
    "        for playlist_id in tqdm(self.playlists.index): \n",
    "            \n",
    "            tracks_playlist = self.tracks[self.tracks.playlist_id == playlist_id]\n",
    "            \n",
    "            indexes = self._get_index(tracks_playlist.id)\n",
    "            tracks_similarity[np.ix_(indexes, indexes)] = squareform(pdist(tracks_playlist, \n",
    "                                                                           metric = metric_songs))\n",
    "        \n",
    "        self.tracks_similarity = tracks_similarity\n",
    "        \n",
    "    def predict(self, given_tracks: pd.DataFrame, n_of_songs: int, show_bar = True):\n",
    "        \n",
    "        n = len(given_tracks)\n",
    "        \n",
    "        if show_bar: \n",
    "            for playlist_item in tqdm(range(n, n_of_songs + n)):\n",
    "\n",
    "                indexes = self._get_index(given_tracks.id)\n",
    "                similarity = self.tracks_similarity[indexes]\n",
    "                track_chosen = self.get_similar_track(similarity)\n",
    "                track_chosen = self._get_track_number(track_chosen)\n",
    "\n",
    "                given_tracks = given_tracks.append(self.tracks[self.tracks.id == track_chosen].iloc[0])\n",
    "        else: \n",
    "            for playlist_item in range(n, n_of_songs + n):\n",
    "\n",
    "                indexes = self._get_index(given_tracks.id)\n",
    "                similarity = self.tracks_similarity[indexes]\n",
    "                track_chosen = self.get_similar_track(similarity)\n",
    "                track_chosen = self._get_track_number(track_chosen)\n",
    "                \n",
    "                given_tracks = given_tracks.append(self.tracks[self.tracks.id == track_chosen].iloc[0])                \n",
    "\n",
    "        return given_tracks\n",
    "    \n",
    "    def training_accuracy(self, rate = 0.7): \n",
    "        \n",
    "        for playlist_id in tqdm(self.playlists.index): \n",
    "            \n",
    "            testing_prediction = self.tracks[self.tracks.playlist_id == playlist_id]\n",
    "            \n",
    "            n = len(testing_prediction)\n",
    "            if n == 0: \n",
    "                continue\n",
    "            \n",
    "            # Already known tracks\n",
    "            j = int(rate*n)\n",
    "            \n",
    "            prediction = self.predict(testing_prediction.iloc[0:j], n - j, \n",
    "                                      show_bar = False)\n",
    "            \n",
    "            assert len(prediction) == n\n",
    "        \n",
    "            phat = set(prediction.id)       # Predicted tracks\n",
    "            p = set(testing_prediction.id)  # Tracks in the training set\n",
    "            \n",
    "            acc = self.accuracy_metric(phat, p, n, j)\n",
    "            self.playlists.loc[playlist_id, 'rate_of_hits'] = acc\n",
    "        \n",
    "        return np.mean(self.playlists.rate_of_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(playlists_df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for the testing!\n",
    "\n",
    "playlist_subset = playlists_df.sample(frac = 0.7, random_state = 100)\n",
    "tracks_subset = tracks_df[features + ['id', 'playlist_id']]\n",
    "tracks_subset = tracks_subset.drop_duplicates(['id', 'playlist_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimilarityModel(tracks_subset, playlist_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd0baa7fad642cbb4580149ac3e81fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eb6dc6af1143808635ee69fb4a62f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7026.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = model.training_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899470013360571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11538.400653839111\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - t0)\n",
    "del t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (espotifai)",
   "language": "python",
   "name": "espotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
