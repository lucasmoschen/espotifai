{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Natrix\n",
    "\n",
    "## Based on the article [PATS](http://ismir2002.ircam.fr/proceedings/OKPROC02-FP07-4.pdf)\n",
    "\n",
    "The ideia is to establish a similarity metric and build a matrix to get playlists.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.cluster import AffinityPropagation, SpectralClustering, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist, squareform, pdist\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from seaborn import heatmap \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Important Features \n",
    "\n",
    "This features will be used to understand the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =  ['playlist_id', 'duration_ms', 'explicit', 'id', 'album_type', 'popularity', 'album_id', \n",
    "             'album_release_date', 'artists_ids', 'name', 'artists_names']\n",
    "audio_features = ['danceability', 'energy', 'loudness', 'key', 'mode', 'speechiness', 'acousticness', \n",
    "                  'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist and tracks dataframes \n",
    "\n",
    "Getting the data generated by Spotify API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_pickle('../data/sp_playlists.pkl')[['owner_id', 'id', 'tracks']]\n",
    "playlists_df.rename(columns = {'id': 'playlist_id', 'tracks': 'n_tracks'}, inplace = True)\n",
    "\n",
    "playlists_df.n_tracks = playlists_df.n_tracks.apply(lambda x: x['total'])\n",
    "\n",
    "# Getting Playlists with at least 5 tracks and maximum of 500 tracks\n",
    "playlists_df = playlists_df[(playlists_df.n_tracks >= 5) & (playlists_df.n_tracks <= 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_df = pd.read_pickle('../data/sp_audio_features.pkl')[audio_features]\n",
    "tracks_df = pd.concat(\n",
    "    [pd.read_pickle(file)[metadata] for file in glob.glob('../data/sp_tracks_ready_*.pkl')],\n",
    "    ignore_index=True\n",
    ")\n",
    "tracks_df = audio_features_df.merge(tracks_df, on = 'id')\n",
    "del audio_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I convert the dates to datetime and use the year as a continuum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['album_release_date'].replace(to_replace = '0000', value = None, inplace=True)\n",
    "tracks_df['album_release_date'] = pd.to_datetime(tracks_df['album_release_date'])\n",
    "tracks_df['album_release_date'] = (tracks_df['album_release_date'] - tracks_df['album_release_date'].min())\n",
    "tracks_df['days'] = tracks_df['album_release_date']/np.timedelta64(1,'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45 nan values in the years columns. I will put the mean of the values, because it's few missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['days'].fillna(np.mean(tracks_df['days']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the artists to set, in order to follow the metric presented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.artists_ids = tracks_df.artists_ids.apply(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separate the catefortical, numerical and set_oriented features, to make the ideia of the similarity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical =  ['explicit', 'album_type', 'album_id', 'key', 'mode', 'time_signature']\n",
    "features_numerical = ['duration_ms', 'popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'days']\n",
    "features_set_oriented = ['artists_ids']\n",
    "\n",
    "features = [] \n",
    "features.extend(features_categorical)\n",
    "features.extend(features_numerical)\n",
    "features.extend(features_set_oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only to ensure correct type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df[features_numerical] = tracks_df[features_numerical].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the metrics proposed. For now, I normalize the numerical data, ensuring the range to be $[0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tracks_df[features_numerical] = scaler.fit_transform(tracks_df[features_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_categorical = lambda x1,x2:  x1 == x2\n",
    "metric_set_oriented = lambda x1, x2: len(x1 & x2)/(len(x1.union(x2)))\n",
    "metric_numerical = lambda x1, x2: 1 - abs(x1 - x2)\n",
    "\n",
    "# Ideia: I will give grades of importance (1 - 5) based on my experience to each feature. \n",
    "# Arbitrary choice\n",
    "weights = [1, 1, 5, 2, 3, 3, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 5]\n",
    "weights = np.array(weights)/sum(weights)\n",
    "\n",
    "def metric_songs(x: np.array, y: np.array) -> float: \n",
    "    \n",
    "    similarity = 0\n",
    "    similarity += np.dot(weights[0:6], metric_categorical(x[0:6], y[0:6]))\n",
    "    similarity += np.dot(weights[6:18], metric_numerical(x[6:18], y[6:18]))\n",
    "    similarity += weights[18]*metric_set_oriented(x[18], y[18])\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example :\n",
    "\n",
    "\n",
    "Let's calculate a simple case with two songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6429353  0.67196831]\n",
      " [0.67909603 0.67121037]\n",
      " [0.71947156 0.67978537]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array(tracks_df[features].iloc[27:30])\n",
    "x2 = np.array(tracks_df[features].iloc[1003:1005])\n",
    "matrix = cdist(x1, x2, metric = metric_songs)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation based on similarity. \n",
    "\n",
    "We will use the metric described above. The similarity between two songs will be interpreted as a **probability**. We could build the role track similarity but it requires much computation. So I will do a simple modification. I will calculate the metric between two songs if they are in the same playlist, for some playlist in the dataset. I expect it reduces the number of calculations! After, we will have a sparser matrix and in order too add tracks to a playlist, we will add iteratively. With a list with n songs, we have the similarities with all tracks. It will be zero when the tracks aren't in the same playlist, for all playlists. We mutiply these probabilities for all tracks (it will be our likelihood) and maximeze it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "class SimilarityModel:\n",
    "    \n",
    "    def __init__(self, tracks: pd.DataFrame, playlists: pd.DataFrame): \n",
    "        '''Function with the implementation of the Simmilarity Model described above. \n",
    "           The metric used are describe in PATS article. \n",
    "           - tracks: all the tracks in your world. \n",
    "           - playlists: the training playlists.\n",
    "        '''\n",
    "        \n",
    "        self.tracks = tracks\n",
    "        self.playlists = playlists\n",
    "        # We will consider a dataframe with the unique tracks and create numerical indexes\n",
    "        self.tracks_index = self.tracks[['id']].drop_duplicates('id').reset_index()\n",
    "        self.playlists = self.playlists.set_index('playlist_id')\n",
    "        \n",
    "    def get_similar_track(self, tracks_similarity: np.array, n_of_songs: int) -> int: \n",
    "\n",
    "        # With this mask, we get only the columns with all lines having values\n",
    "        #counting_elements = tracks_similarity.getnnz(axis = 0)\n",
    "        #mask = counting_elements == tracks_similarity.shape[0]\n",
    "        #interest_tracks = np.zeros(tracks_similarity.shape[1], dtype = float)\n",
    "        interest_tracks = tracks_similarity.mean(axis = 0).A.flatten()\n",
    "        songs = np.argpartition(interest_tracks, -n_of_songs)[-n_of_songs:]\n",
    "        return songs\n",
    "    \n",
    "    def _get_index(self, tracks_ids):\n",
    "        \n",
    "        indexes = self.tracks_index[self.tracks_index.id.isin(tracks_ids)].index\n",
    "        \n",
    "        return list(indexes)\n",
    "    \n",
    "    def _get_track_number(self, index):\n",
    "        \n",
    "        track_id = self.tracks_index.loc[index]\n",
    "        return track_id.id\n",
    "    \n",
    "    def accuracy_metric(self, yhat, ytrue,n, j):\n",
    "\n",
    "        acc = (len(ytrue & yhat) - j)/(n - j)\n",
    "        return acc\n",
    "     \n",
    "    def fit(self): \n",
    "        '''This functions build the model with the tracks and playlists disposed. '''\n",
    "        \n",
    "        tracks_similarity = lil_matrix((len(self.tracks_index), len(self.tracks_index)), \n",
    "                                       dtype = float)\n",
    "        \n",
    "        for playlist_id in tqdm(self.playlists.index): \n",
    "            \n",
    "            tracks_playlist = self.tracks[self.tracks.playlist_id == playlist_id]\n",
    "            \n",
    "            indexes = self._get_index(tracks_playlist.id)\n",
    "            tracks_similarity[np.ix_(indexes, indexes)] = squareform(pdist(tracks_playlist, \n",
    "                                                                           metric = metric_songs))\n",
    "        \n",
    "        self.tracks_similarity = tracks_similarity\n",
    "        \n",
    "    def predict(self, given_tracks: pd.DataFrame, n_of_songs: int):\n",
    "        \n",
    "        n = len(given_tracks)\n",
    "        \n",
    "        indexes = self._get_index(given_tracks.id)\n",
    "        similarity = self.tracks_similarity[indexes]\n",
    "        tracks_chosen = self.get_similar_track(similarity, n_of_songs)\n",
    "        for track in tracks_chosen: \n",
    "            track_id = self._get_track_number(track)\n",
    "            given_tracks = given_tracks.append(self.tracks[self.tracks.id == track_id].iloc[0])              \n",
    "\n",
    "        return given_tracks\n",
    "    \n",
    "    def training_accuracy(self, playlists: pd.DataFrame = None,rate = 0.7): \n",
    "        \n",
    "        accuracy = []\n",
    "        if playlists is None:\n",
    "            playlists = self.playlists\n",
    "        \n",
    "        for playlist_id in tqdm(playlists.index): \n",
    "            \n",
    "            testing_prediction = self.tracks[self.tracks.playlist_id == playlist_id]\n",
    "            \n",
    "            n = len(testing_prediction)\n",
    "            if n == 0: \n",
    "                continue\n",
    "            \n",
    "            # Already known tracks\n",
    "            j = int(rate*n)\n",
    "            \n",
    "            prediction = self.predict(testing_prediction.iloc[0:j], n - j)\n",
    "            \n",
    "            assert len(prediction) == n\n",
    "        \n",
    "            phat = set(prediction.id)       # Predicted tracks\n",
    "            p = set(testing_prediction.id)  # Tracks in the training set\n",
    "            \n",
    "            acc = self.accuracy_metric(phat, p, n, j)\n",
    "            \n",
    "            accuracy.append(acc)\n",
    "        \n",
    "        return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Results\n",
    "\n",
    "First, I will get `playlist_id` for train and test. I get also only the necessary features from the tracks. \n",
    "I drop the duplicates cause I'm not interested in playlists with repeated tracks, given that I already know two equal songs have similarity 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(playlists_df.drop_duplicates().sample(frac = 0.01))\n",
    "tracks_subset = tracks_df[features + ['id', 'playlist_id']]\n",
    "tracks_subset = tracks_subset.drop_duplicates(['id', 'playlist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimilarityModel(tracks_subset, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912167420e5a4db78f5c14eb9e65de68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the accuracy of the predicted songs for each playlist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965f1128bfa5439ba4e3cfeb0cc294ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.751512730425017\n"
     ]
    }
   ],
   "source": [
    "acc = model.training_accuracy()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see in the testing set\n",
    "\n",
    "I only have to set test index to `playlist_id` because it is only done automatically in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('playlist_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e2ecd9107c4b739f1cd376e9036f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.001388888888888889\n"
     ]
    }
   ],
   "source": [
    "test_acc = model.training_accuracy(test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (espotifai)",
   "language": "python",
   "name": "espotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
